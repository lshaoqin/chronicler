# Chronicler Environment Configuration Example
# Copy this file to .env and update with your actual values

# ===== LLM Provider Configuration =====

# You can configure LLM and embedding providers separately or use a single MODEL_PROVIDER
# If LLM_PROVIDER or EMBEDDING_PROVIDER are not set, they will fall back to MODEL_PROVIDER

# LLM provider selection ('openai', 'gemini', 'ollama', or 'local')
# - 'openai': Uses OpenAI's cloud models (requires OPENAI_API_KEY)
# - 'gemini': Uses Google's Gemini models (requires GOOGLE_API_KEY)
# - 'ollama': Uses locally running Ollama models (requires OLLAMA_HOST)
# - 'local': Uses locally running Ollama models (requires OLLAMA_HOST)
LLM_PROVIDER=openai

# Embedding provider selection ('openai', 'gemini', 'ollama', or 'local')
# - 'openai': Uses OpenAI's embedding models (requires OPENAI_API_KEY)
# - 'gemini': Uses Google's embedding models (requires GOOGLE_API_KEY)
# - 'ollama': Uses locally running Ollama models for embeddings (requires OLLAMA_HOST)
# - 'local': Uses HuggingFace Sentence Transformers for embeddings (local)
EMBEDDING_PROVIDER=openai

# Legacy model provider (used as fallback if LLM_PROVIDER or EMBEDDING_PROVIDER are not set)
# MODEL_PROVIDER=openai

# LLM model name to use
# - For OpenAI: 'gpt-4o', 'gpt-4', 'gpt-3.5-turbo', etc.
# - For Gemini: 'gemini-1.5-pro', 'gemini-1.5-flash', etc.
# - For Ollama: 'llama2', 'mistral', 'codellama', etc.
LLM_MODEL=gpt-4o

# Embedding model name to use
# - For OpenAI: 'text-embedding-ada-002'
# - For Gemini: 'embedding-001'
# - For Ollama: Embedding model of choice, e.g. 'nomic-embed-text', 'llama2'
# - For local: 'all-MiniLM-L6-v2' or other HuggingFace Sentence Transformers models
EMBEDDING_MODEL=text-embedding-ada-002

# OpenAI API Key (required for OpenAI provider)
OPENAI_API_KEY=your_openai_api_key

# Google API Key (required for Gemini provider)
GOOGLE_API_KEY=your_google_api_key

# Ollama configuration (required for Ollama provider)
OLLAMA_HOST=http://localhost:11434

# ===== Vector Database Configuration =====

# Select the vector database type (uncomment one)
VECTOR_DB_TYPE=faiss
# VECTOR_DB_TYPE=pinecone
# VECTOR_DB_TYPE=weaviate
# VECTOR_DB_TYPE=chroma
# VECTOR_DB_TYPE=qdrant
# VECTOR_DB_TYPE=milvus

# ===== Pinecone Configuration =====
# Required if VECTOR_DB_TYPE=pinecone
# PINECONE_API_KEY=your_api_key
# PINECONE_ENVIRONMENT=your_environment  # e.g., us-west1-gcp
# PINECONE_INDEX_NAME=your_index_name
# PINECONE_NAMESPACE=your_namespace  # Optional, defaults to "default"

# ===== Weaviate Configuration =====
# Required if VECTOR_DB_TYPE=weaviate
# WEAVIATE_URL=your_weaviate_url  # e.g., https://your-instance.weaviate.network
# WEAVIATE_API_KEY=your_api_key  # Optional if authentication is not required
# WEAVIATE_INDEX_NAME=Chronicler  # Optional, defaults to "Chronicler"
# WEAVIATE_TEXT_KEY=content  # Optional, defaults to "content"

# ===== Chroma Configuration =====
# Required if VECTOR_DB_TYPE=chroma
# CHROMA_PERSIST_DIRECTORY=./chroma_db  # Optional, defaults to "./chroma_db"
# CHROMA_COLLECTION_NAME=chronicler  # Optional, defaults to "chronicler"

# ===== Qdrant Configuration =====
# Required if VECTOR_DB_TYPE=qdrant
# QDRANT_URL=your_qdrant_url  # e.g., http://localhost:6333
# QDRANT_API_KEY=your_api_key  # Optional if authentication is not required
# QDRANT_COLLECTION_NAME=chronicler  # Optional, defaults to "chronicler"

# ===== Milvus Configuration =====
# Required if VECTOR_DB_TYPE=milvus
# MILVUS_URI=your_milvus_uri  # e.g., http://localhost:19530
# MILVUS_COLLECTION_NAME=chronicler  # Optional, defaults to "chronicler"
# MILVUS_USERNAME=your_username  # Optional
# MILVUS_PASSWORD=your_password  # Optional
